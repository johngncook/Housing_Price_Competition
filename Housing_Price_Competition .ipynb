{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from warnings import simplefilter\n\nsimplefilter(action='ignore', category=FutureWarning)\n\nimport numpy as np \nimport pandas as pd \nimport  matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom datetime import datetime\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ndf_test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ndf.head(20) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns #Overview of columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_list = df.isnull().sum().sort_values(ascending=False) #check for nulls\n\nfull_list.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing data\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr = df.corr() #create heatmap to asses which features corrolate the most with sale price\nf, ax = plt.subplots(figsize=(40, 15))\nsns.heatmap(df_corr, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = 10 #number of variables for heatmap\ncols = df_corr.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_features = df[['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath','TotRmsAbvGrd','YearBuilt']]\nplt.figure(figsize=(30,30))\ni = 1\n\nfor numerical_feature in numerical_features:\n    plt.subplot(3,3,i)\n    i=i+1\n    \n    sns.scatterplot(x=numerical_features[numerical_feature], y=df['SalePrice'])\n    \n    plt.title(str(numerical_feature))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors = df.drop(['SalePrice','Id'], axis=1) #define variables and split data\ntarget = df[\"SalePrice\"]\ntest_data = df_test.drop(['Id'], axis=1)\n\nx_train, x_valid, y_train, y_valid = train_test_split(predictors, target, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in x_train.columns if\n                    x_train[cname].nunique() < 10 and \n                    x_train[cname].dtype == \"object\"]\n\n\n# Select numerical columns\nnumerical_cols = [cname for cname in x_train.columns if \n                x_train[cname].dtype in ['int64', 'float64']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='most_frequent')\n\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Choose best model to use\nxgb = XGBRegressor()\nrf = RandomForestRegressor()\ndtree = DecisionTreeRegressor()\n\nmodels = [xgb,rf,dtree]\n\n\n\n\nfor model in models:\n    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),# Bundle preprocessing and modeling code in a pipeline\n                      ('model', model)])\n    \n    my_pipeline.fit(x_train, y_train,) \n    train_preds = my_pipeline.predict(x_train)\n    test_preds = my_pipeline.predict(x_valid) \n    print('Model Report')\n    print('\\n',str(model))\n    print('\\nTraining accuracy:', r2_score(y_train, train_preds))\n    print('Test accuracy:', r2_score(y_valid, test_preds))\n  \n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def timer(start_time=None): #Define timer function\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameter grid for XGBoost\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'colsample_bynode': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Randomized search CV\nfolds = 3\nparam_comb = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, n_jobs=4, cv=skf.split(x_train,y_train), verbose=3, random_state=1001 )\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', random_search)])\n\n\n\nstart_time = timer(None) # timing starts from this point for \"start_time\" variable\nmy_pipeline.fit(x_train, y_train)\ntimer(start_time) # timing ends here for \"start_time\" variable\n\nprint('\\n All results:')\nprint(random_search.cv_results_)\nprint('\\n Best estimator:')\nprint(random_search.best_estimator_)\nprint('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\nprint(random_search.best_score_ * 2 - 1)\nprint('\\n Best hyperparameters:')\nprint(random_search.best_params_)\nresults = pd.DataFrame(random_search.cv_results_)\nresults.to_csv('xgb-random-grid-search-results-01.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = random_search.best_estimator_\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', xgb)])\n    \nmy_pipeline.fit(x_train, y_train,) \ntrain_preds = my_pipeline.predict(x_train)\ntest_preds = my_pipeline.predict(x_valid) \nprint('Model Report')\nprint('\\n',str(model))\nprint('\\nTraining accuracy:', r2_score(y_train, train_preds))\nprint('Test accuracy:', r2_score(y_valid, test_preds))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = my_pipeline.predict(test_data) #Get test predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': df_test['Id'],\n                       'SalePrice': test_predictions})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}